---
title: What is AI?
layout: post
---

My last post elicited some feelings. Let's see if this one can be productive without alerting the police.

I've been trying to encircle what I'm talking about when I'm talking about a certain thing. If I get any more specific than that, I think I'm going to give away the ending, and I really want to take this post slowly and work through how I ended up where I am.

Several people challenged me on my understanding of what AI is. And, to their credit, I didn't define what AI is! Because I didn't want to. At Logic(s) we've adopted a policy not to call something "AI" if we mean something more precise, and it is almost always the case that we mean something more precise than "AI". But in much of my work, I mean *something* that is precisely... *something*.

Let me try and make this more tangible.

Let's introduce a few terms:

- Machine Learning (ML): 
- Large Language Models (LLMs): 
- Model: 














In my last post I offered a modest proposal - that we should develop more vocabulary for the destruction of harmful systems, particularly AI systems that offer no meaningful recourse, escape, or circumvention around those systems. I was surprised (mostly pleasantly) by the response, but something came up repeatedly, and I figured it might be useful to lay out a few definitions. I want to start with "artificial intelligence".

I think it's worth nailing down precisely what I mean when I invite you to [destroy "AI"][destroyAI] because it became clear very early on that people operate with very different definitions of what "artificial intelligence" even is. This is a problem because I got replies from people who seemed to think I was advocating against mathematics, or against statistical modeling, or against computers. Some people advocate for that and I think they make compelling arguments, but that's not what *I'm* arguing, so let's at least set that straight.

Before I get into it, I also want to point out that a term should offer a definition that serves a unique purpose. Two terms or two words can have the same verbatim textual definition, but they should at least serve different purposes in conversations.

There's also something weird pushing from the other direction: I have an intuition of things that I would point to that I know I *want* to capture when I talk about this broad thing, so no matter what happens, I need my definition of "AI" to manage to encircle that stuff.

This is all to say that if we're using "Machine Learning" (ML) and "Large Language Models" (LLMs) and "Artificial Intelligence" (AI) interchangeably and indiscriminately, then I think we're going to stumble into spaces where we actually mean LLMs specifically, but don't mean ML. Or we'll talk about ML and not *just* mean LLMs, nor mean AI.

Or, to say it from the other side, if I'm trying to come up with a name for all the chatbots - ELIZA, Chat-GPT, Claude, etc... - then I need a word that isn't constrained by technical implementations and whatnot. ELIZA wasn't an LLM, nor did it use ML, so it might be wrong to define AI in relation to those things if I'm trying to include ELIZA in the word I'm trying 

So this is pretty basic philosophical navel-gazing - words should mean things, or whatever. That brings me to the question: what does AI mean?

I think someone could say that "an AI is the synthesis of an ML system and the data that goes into the system" - in other words, kind of referencing the *models* that underpin chatbots like chat-GPT, Claude, etc...

I think that's *fine*, and if you want to go with that definition, feel free (please just say so when you're writing about AI). But for me, it's enough to call those things "models".

For me, "AI" must refer to something more encompassing than just the data and the modeling system that synthesizes and turns that data into a model. I spent some time trying to figure out why some things intuitively seem